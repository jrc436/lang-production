\section{Language Production Model}
The goal of the jACT-­R model of language production is to expand cognitive modelling to the full range of realizations found in a corpus. This can be accomplished by learning various linguistic elements from corpora.

\subsection{Model Representation}
The fundamental assumption of the model is that a syntax rule is a type of production rule. This, in turn, assumes that language production is driven by some type of grammar, though we do not claim there is anything inherent, fundamental, or universal about this grammar.

Our methodology attempts to avoid other fundamental assumptions, including the exact nature of the combinatory mechanism. However, early versions of this model rely on Combinatory Categorial Grammar (CCG) \cite{ccg} for the basic syntax rules.

From the corpus, the model learns the dictionary and the range of types. As CCG has few syntax rules, but many syntactic types, the model learns what types are associated with which lexical entries from the corpus.

\subsection{Experimental Paradigm}
The goal of the model, ultimately, is to create a model that can change a semantic representation of a sentence into a fully realized sentence, using the same processes as humans. This means that ultimately, it's not just important that the model produces a sentence with the same meaning, but that it realizes the sentence in the same way a human would. Ultimately, our evaluation would then consider using a metric like edit distance. Due to uncertainty in syntactic rule choice, we would never expect the model to choose the realize the exact same sentences as are found in the corpus; however, this allows us to compare among possible models.

Unfortunately, There are limitations in generating accurate semantic representations from arbitrary sentences in corpora. Therefore, we are presently in the process of refining a model that tries to produce a sentence from a set of words, instead of trying to produce a sentence with a given meaning. While these words come from a corpus sentence, the model receives no ordering or semantic information. This allows us to explore various syntactic features of language production, while largely ignoring the lexical and semantic features.

One such syntactic feature is incrementality. This refers to the order in which syntax rules are applied when creating the mental representation of a sentence. This feature is also interesting due to conflicting opinions and evidence \cite{tag1}\cite{radical}\cite{incremental}. A principled linguist, using CCG, can create at least two different derivations: normal ­form and incremental form. The former has certain nice computational properties, while the latter always attempts to combine the words in order.

\subsection{Current Experiment}
While we are currently devising a methodology to test between these two, we have completed a simpler analysis that's based purely on the sentence positions in the original sentence. We test five conditions, described as Early, Middle, Late, Default, and Control. These conditions are based on giving syntax rules in sentence position \textit{i} some amount of initial utility, using the ACT-R system. These positions correspond to positions in the input sentence. This is possible because production rules, rather than corresponding to exactly one syntax rule, correspond to a syntax rule at sentence position \textit{i}.

\subsubsection{Early}
The Early condition means that sentence position \textit{1} gets \textit{N} initial utility, then sentence position \textit{i+1} gets \textit{N/2} utility.

\subsubsection{Middle}
The Middle condition means that sentence position \textit{LENGTH/2} gets \textit{N} initial utility, then sentence positions \textit{i+1} and \textit{i-1} both get \textit{N/2} utility.

\subsubsection{Late}
The Late condition means that sentence position \textit{LENGTH} gets \textit{N} initial utility, then sentence position \textit{i-1} gets \textit{N/2} utility.

\subsubsection{Default}
Default means that all sentence positions start with equal utility, besides some amount of noise.

\subsubsection{Control}
Control refers to the actual input sentences, rather than the sentences produced by the model.

\subsubsection{Evaluation}
Our evaluation relies first on computing the ngram scores for each of the sentences produced. While, at the level of an individual sentence this represents probability, rather than plausibility, the distribution itself could represent the range of sentences that a human would produce. Then, our goal was to use a Wilcox test to determine if these scores come from the same distribution.

We evaluated approximately 650 sentences per condition using a simple ngram measure from the SRILM toolkit \cite{srilm}. The Early sentences had the best ngram scores, but the standard deviation was quite high, and the distribution was indeed very non-­normal. We found, in short, that Early and Middle conditions patterned together, the Late and Default conditions patterned together, and none of them patterned with the Control. 

\begin{tabular}{l|cc}
Condition-Pair & w-score & p-value \\ \hline
Early-Default & 160050 & <0.00001 \\
Early-Control & 499320 & <0.00001 \\
Early-Middle & 2238700 & 0.1702 \\
Early-Late & 177950 & <0.00001 \\
Middle-Late & 177950 & <0.00001 \\
Middle-Default & 161410 & <0.00001 \\
Middle-Control & 493680 & <0.00001 \\
Default-Late & 229670 & 0.0342 \\
Default-Control & 541230 & <0.00001 \\
Late-Control & 545950 & <0.00001 
\end{tabular}
