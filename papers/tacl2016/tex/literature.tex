\section{Previous Work}
\subsection{Theories of Incrementality}
It is a commonly implied assumption that language processing proceeds incrementally. In grammatical encoding, this property concerns when and in which order syntactic choices are made. For instance, all of them could be made before  phonological processing starts (non-incremental case), or they could be made in order as necessary. In comprehension, the surface form becomes available incrementally; in language production, semantic material may or may not be fully available at the start. However, memory buffers are insufficient to plausibly retain the entire structure and surface forms of longer sentences in either case. Existing high-level models of language production proceed incrementally at various steps in a chain of content selection, aggregation and sentence realization (Bock \& Levelt, 2002; Guhe, 2007).

V. S. Ferreira (1996) makes an argument for incrementality, based on the observation that competitive syntactic alternatives facilitate production rather than making it more difficult. An incremental account of sentence realization would predict such an effect, as syntactic “flexibility” introduced by the alternatives makes it easier to find a workable syntactic decision. By contrast, without incremental commitment to each structure, competing material slows down the process, because it would lead to a combinatory explosion. Further results, however, relativize this account when it comes to the syntax-phonology interface (F. Ferreira \& Swets, 2002): Incremental production is possible, but it is “under strategic control”; it depends on semantic information, and it could be modulated by external factors, such as stress.

Syntactic priming can shed further light on the incrementality of these processes. Figure 1 shows how Combinatory Categorial Grammar (CCG) can analyze a sentence with many degrees of incrementality; meanwhile, it is generally possible to find syntactic priming of CCG categories. Therefore, we can shed light on the internal language production strategy with this combination of psycholinguistic effect and linguistic representation. \citet{ReitterHock2006} uses CCG to contrast priming of syntactic categories in incremental and non-incremental derivations. In the previous study, incremental derivations were favored in comprehension, but not in production. It is likely that a more complete model can be found: we suggest that comprehension nor production are purely incremental processes. 

However, based on these experiments, incrementality in grammatical encoding is likely graded. Our model has the potential to explain why: it could be the result of grammatical availability, activation of grammatical structures, routinization, working memory use, and semantic availability. While we explore several of these , the answer is certainly not definitive. As the model gains more fidelity and higher coverage, it will also gain more explanatory power. 

\subsection{Cognitive Models}
Language processing, in terms of both comprehension and production, have been explored broadly by the cognitive modeling community.

In terms of comprehension, cognitive models have been created both to explain several phenomenon and more generally. \citet{decision} explained the lexical decision task as a by-product of chunk activation. \citet{anaphoric} provides evidence that memory retrieval is likewise sufficient to explain whether nouns are treated as anaphoric: whether they refer to an antecedent or are a new reference. Both \citet{comp-model} and \citet{big-comprehension} make strides toward more general models of language comprehension.

However, the models to explain phenomena in language production are more narrow. \citet{references} created a model that produced references for the iMAP task. \citet{model-priming} was a cognitive model of syntactic priming; it demonstrated that priming can be explained by activation. It made linguistic choices, but only well-defined choices, such as whether to choose double object or prepositional object constructions. 

While broader coverage models of language generation do exist \citep{chart}, they make no claims of cognitive plausibility. Thus, we see our work as a step towards a broad, realistic model of language production. 