\section{Introduction}
 How does the mind select words, sequence them, and produce sentences that communicate our intentions within context? The search for answers to this question has led researchers to a variety of models. Many models of psychology describe information processing and exchange; most linguistic models describe the representations that drive the process. The models explain empirical, qualitative observations; the fields have also developed quantitative metrics for evaluation. Obviously, models are underspecified in that they do not contain a computational (algorithmic) account that can carry out the process and predict testable effects. Specifically, a computational-psycholinguistic model of grammatical encoding has yet to emerge. The search for computational models that address related questions has been re-invigorated in recent years as large-scale language data have become available. This paper advances a computational cognitive model of grammatical encoding in language production by integrating work from somewhat separate fields. It uses a validated cognitive framework as well as broad-coverage grammars used by computational linguists, together with corpus-based evaluation techniques.
 
 This model is intended to be a starting point. Eventually, this model can help advance our understanding of language production by providing a unified model of several quite distinct effects. It will be quantitatively and architecturally plausible because it will be formulated within a cognitive framework, ACT-R (Newell, 1994; Anderson et al., 2004). This will make relationships between general cognition and memory and language processing clear. The model also uses insights from computational linguistics as it leverages a broad-coverage grammar formalism, CCG (Steedman, 2000). In this way, the model has the potential to advance theories in the field; however, it is presently only an advance in methodology. Similar models have been created to explain psycholinguistic theories as part of more general cognitive effects: for instance, syntactic priming as a product of cue-based memory retrieval \cite{priming-model}. 
 
However, while that model effectively explained one phenomenon, it could not produce the linguistic range found in corpora. Thus, more subtle linguistic phenomenon could not emerge. While explaining current data is required for any proposed model, the ultimate goal is prediction. A large range of possible models can explain all available data; however, by making testable predictions, a model can be validated beyond its peers.
 
\section{Motivation}
In the introduction to a volume reporting on the state of research in the field, psychologist Linda Wheeldon points out that language production “boasts a dedicated, imaginative, and highly productive group of researchers”, yet still lacks connection to other work, such as cognitive modeling. She also emphasized “the need for psychological models of language production to learn from theoretical linguistics in order to become better informed about the structure of language itself” (Wheeldon, 2000). A decade and a half later, researchers in computational psycholinguistics have dedicated themselves to the task of the interdisciplinary integration that Wheeldon called for. However, in language production, there is a need to combine the study of language, cognitive architecture, and linguistics.

Computational psycholinguistics has, in recent years, discovered a range of phenomena that may shape how we think about the mechanisms of human language acquisition and language processing. These phenomenon have origins ranging from information theory to learnability and have provoked important questions. As cognitive linguists ask ”How incremental is language production?” or ”How do people utilize working memory when realizing sentences?”, the boundaries are slowly being pushed for models to incorporate the full expressive range found in corpora. Meanwhile, while experiments have provided some answers to these questions, language production is particularly susceptible to experimental design. Without providing templates of some sort, such as \citet{sums-incr}\citet{prod-exp}, experimenters risk having too little data to answer their questions. However, providing templates eliminates an important piece of language production. Most critically, it is not yet clear if template selection is even a discrete step. If it is not, then by providing the template, it is possible that researchers are not simply eliminating one step from the task of language production but are changing the task to something else entirely. Thus, cognitive modelling is uniquely suited to answer questions when the design of the experiment moves the task too far from its naturalistic state. 

For example, consider an experimenter who wishes to contrast the choice of a Double Object construction (The boy threw his dog the ball) with a Prepositional Object construction (The boy threw the ball to his dog). If the participant is simply describing a picture, there is no guarantee he or she will even reference the dog! While these controls have been useful, they could have the side effect of muddling certain parts of the process: such as planning. In order to produce a sentence, it must first be planned. Investigating the planning process is difficult: many paradigms frequently used to investigate sentence comprehension, such as eye tracking or the visual world, seem much more difficult to apply. Despite the difficulty in designing experiments to measure planning, it is clearly of interest to researchers, as can be evidenced by ongoing debates. One such debate is to what degree is the process \emph{incremental}. 
 
For instance, with sentences that contain center-embedded clauses, is the end planned before or after the embedded clause? Consider the sentence "The dog that was chasing the cat that seemed to have rabies fell over." An incremental derivation would rely on \emph{surface order}: the actual order the words appear in the sentence. In other words, the speaker first plans "the dog", then "that was chasing the cat", then "that seemed to have rabies" and lastly "fell over." A less incremental derivation might be to plan "fell over" immediately after "the dog", and then to add the clauses later.
 
These questions are controversial, prompting ideas without clear cut answers. Due to the seeming difficulty in solving this debates such as these with more experimentation, we suggest turning to computational cognitive modeling, with a focus on models that are broad-coverage and can be empirically evaluated.
 
%