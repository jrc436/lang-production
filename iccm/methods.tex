\section{Methods}
\subsection{Goals}
Our goal is to achieve this using the tight constraints of the ACT-R system \citep{actr}. We further attempt to stick within the constraints of plausibility by not relying on strategies such as resampling from previously heard input, due to its inability to produce novel productions. Instead, we define a range of operations that are defined in the Combinatory Categorial Grammar (CCG) \citep{ccg}, a minimally context sensitive grammar that is believed to be capable of all of the syntactic operations of human language \citep{convergence}. However, while our current system uses the operations of CCG, our theoretical basis of combinatory operations does not explicitly rely on CCG. Indeed, our system could in the future compare two combinatory systems for plausibility. Our longterm goals take nothing for granted: any operation, method, or structure that is cognitively plausible, fits the data, and produces realistic output is a possibility. 

In the short term, however, we make several assumptions about the operations and structure of language production. The model attempts to combine whatever words it wants, given its current settings, rules, chunks, and goals. It is natural for the model to make some mistakes, but it can still be compared with itself for \textit{plausibility}.

\subsection{Evaluation}
The model receives as input a set of words that made up a sentence in the Switchboard corpus. The model will then, using its knowledge about these words and possible combinatory operations, attempt to produce a sentence or sentence fragment. The goal is to be more plausible, though this is obviously somewhat difficult and controversial to measure. Our method was to average the bigram scores produced by the SRILM toolkit \citep{srilm} for a given sentence. We used the same method for evaluation as used by \citet{chart}. Then, we computed standard statistical metrics on the distribution of these scores: namely the mean, median, and standard error.

As the models are generating from the same bag of words, there should be no serious disadvantage to choosing uncommon but naturalistic phrases, especially over a large dataset. 

\subsection{ACT-R}
ACT-R has a few basic units of organization. The primary units for declarative memory are \textit{chunks}. A chunk is a fairly simple concept that basically refers to one thing that can be retrieved or held in working memory. Chunks can be arbitrarily simple or complicated by way of \textit{slots}. A slot is a simple data type that corresponds to another chunk. The most primitive chunks thus have a name, but no slots. 

Buffers are a unit of cognition that can hold exactly one chunk. While ACT-R can, in theory, have an arbitrary number of buffers (including those such as the visual buffer or the auditory buffer), we make use of only the simplest buffers: the retrieval buffer and the goal buffer. The retrieval buffer can be thought of as the state of memory retrieval. It can be empty or it can be retrieving something or it can contain something it just retrieved. The goal buffer, on the other hand, can be thought of as working memory. It also can only contain one chunk, but it contains the state of the problem that is being solved. 

Production rules are the allowable manipulations of the buffers, and the conditions upon which those manipulations should be performed. For instance, a model could have a production rule that says to retrieve something when the goal buffer is at some state. It might, for instance, call for looking up the syntactic type of the word that's currently in a given slot in the goal buffer. These production rules, in combination with chunks, form a cognitive model of some task when by meeting these conditions iteratively, they can successfully transform the initial state of the problem into its goal state. 

ACT-R additionally has a couple of other mechanisms. One is a form of simple utility learning, where after a rule fires, it is rewarded, penalized, or neither. We will use this type of learning with the tracing model. Another is activation, which affects which matching chunk is retrieved. This activation can be used to explain many linguistic phenomenon, such as priming \citep{priming} \citep{model}.  

In the following, we'll present the full set of chunks and production rules that make up our model. 